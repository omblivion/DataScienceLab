{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_unique_data(target_dataframe, end_target_columns):\n",
    "    # Get the number of columns\n",
    "    n_cols = target_dataframe.shape[1]\n",
    "\n",
    "    # Get the last 7 columns\n",
    "    df_last_7_columns = target_dataframe.iloc[:, -end_target_columns:]\n",
    "\n",
    "    # Create a dictionary to store the unique values with their column name\n",
    "    unique_values = {col: df_last_7_columns[col].unique() for col in df_last_7_columns.columns}\n",
    "\n",
    "    # Create a new Series from the dictionary\n",
    "    unique_series = pd.Series(unique_values)\n",
    "    return unique_series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1: Dataframe analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "dev_df = pd.read_csv('development.csv')\n",
    "dev_df.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "#TODO REMOVE ME\n",
    "dev_df = dev_df.sample(frac=0.02, random_state=42)\n",
    "df_unique_data = get_unique_data(dev_df, 7)\n",
    "df_unique_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('evaluation.csv')\n",
    "\n",
    "df_unique_data = get_unique_data(eval_df, 4)\n",
    "df_unique_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "col1_counts = dev_df['First Language spoken'].value_counts()\n",
    "\n",
    "# Count the occurrences of each value in the second column\n",
    "col2_counts = dev_df['Current language used for work/school'].value_counts()\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(col1_counts.index, col1_counts.values, label='First Language spoken')\n",
    "ax.bar(col2_counts.index, col2_counts.values, label='Current language used for work/school', width=0.4, align='edge',\n",
    "       alpha=0.5)\n",
    "\n",
    "# Add a legend and display the chart\n",
    "ax.legend()\n",
    "ax.set_yscale('log')  # this line add the y-axis scaling to logarithmic\n",
    "plt.xlabel(\"Values\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.title(\"Occurrences of Languages in the Development Dataframe, logarithmically scaled\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "col1_counts = eval_df['First Language spoken'].value_counts()\n",
    "\n",
    "# Count the occurrences of each value in the second column\n",
    "col2_counts = eval_df['Current language used for work/school'].value_counts()\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(col1_counts.index, col1_counts.values, label='First Language spoken')\n",
    "ax.bar(col2_counts.index, col2_counts.values, label='Current language used for work/school', width=0.4, align='edge',\n",
    "       alpha=0.5)\n",
    "\n",
    "# Add a legend and display the chart\n",
    "ax.legend()\n",
    "plt.xlabel(\"Values\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.title(\"Occurrences of Languages in the Evaluation dataframe, logarithmically scaled\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2: Dataframe cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev_df.drop(dev_df[dev_df['First Language spoken'] != 'English (United States)'].index, inplace=True)\n",
    "dev_df.drop(dev_df[dev_df['Current language used for work/school'] != 'English (United States)'].index, inplace=True)\n",
    "df_unique_data = get_unique_data(dev_df, 7)\n",
    "df_unique_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sentence(row):\n",
    "    if row[\"object\"] == \"none\":\n",
    "        return row[\"action\"]\n",
    "    else:\n",
    "        return row[\"action\"] + row[\"object\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply the function to the dataframe\n",
    "dev_df[\"sentence\"] = dev_df.apply(create_sentence, axis=1)\n",
    "dev_df.drop('action', axis=1, inplace=True)\n",
    "dev_df.drop('object', axis=1, inplace=True)\n",
    "dev_df.drop('First Language spoken', axis=1, inplace=True)\n",
    "dev_df.drop('Current language used for work/school', axis=1, inplace=True)\n",
    "dev_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_and_clean_audio(filepath):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(filepath)\n",
    "\n",
    "    # Perform any necessary cleaning steps\n",
    "    # for example removing silence at the beginning and end of the audio\n",
    "    yt, _ = librosa.effects.trim(y)\n",
    "\n",
    "    # Return the cleaned audio\n",
    "    return yt\n",
    "\n",
    "\n",
    "def extract_features(filepath):\n",
    "    y = load_and_clean_audio(filepath)\n",
    "    # Extract features from the audio\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=22050, n_mfcc=40)\n",
    "    return np.mean(mfcc, axis=1)\n",
    "\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "        X = load_and_clean_audio(file_name)\n",
    "        sample_rate=X.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract features for each audio file and store them in a new column\n",
    "dev_df['path'].apply(extract_features)\n",
    "dev_df['features'] =\n",
    "dev_df = dev_df.drop(\"path\", axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the ML"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# separate the target variable\n",
    "y = dev_df[\"sentence\"]\n",
    "X = dev_df.drop(\"sentence\", axis=1)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# define the categorical columns\n",
    "categorical_cols = [\"speakerId\",]\n",
    "\n",
    "var = X[categorical_cols].shape()\n",
    "l = pd.get_dummies(X[categorical_cols]).shape()\n",
    "print(var)\n",
    "print(l)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize and train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
